{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example of Using preprocess.py and embedding.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "import preprocess as pre\n",
    "import embedding as em"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "      <th>Average Words Per Comment</th>\n",
       "      <th>Variance of Word Counts</th>\n",
       "      <th>Cleaned Posts</th>\n",
       "      <th>IE</th>\n",
       "      <th>NS</th>\n",
       "      <th>TF</th>\n",
       "      <th>JP</th>\n",
       "      <th>Average Words Per Comment Scaled</th>\n",
       "      <th>Variance of Word Counts Scaled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1228</th>\n",
       "      <td>INFP</td>\n",
       "      <td>'We are mandarin speakers.  He receive educati...</td>\n",
       "      <td>16.78</td>\n",
       "      <td>187.3024</td>\n",
       "      <td>'we are mandarin speakers. he receive educatio...</td>\n",
       "      <td>I</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>P</td>\n",
       "      <td>-1.245319</td>\n",
       "      <td>1.039153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1290</th>\n",
       "      <td>ISTP</td>\n",
       "      <td>'Nope.  Not now, not ever.  I'm too busy with ...</td>\n",
       "      <td>24.38</td>\n",
       "      <td>145.0304</td>\n",
       "      <td>'nope. not now, not ever. i'm too busy with wo...</td>\n",
       "      <td>I</td>\n",
       "      <td>S</td>\n",
       "      <td>T</td>\n",
       "      <td>P</td>\n",
       "      <td>-0.021923</td>\n",
       "      <td>0.161601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6756</th>\n",
       "      <td>ENFJ</td>\n",
       "      <td>'That's the only one I haven't gotten to read ...</td>\n",
       "      <td>23.38</td>\n",
       "      <td>182.9104</td>\n",
       "      <td>'that's the only one i haven't gotten to read ...</td>\n",
       "      <td>E</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>J</td>\n",
       "      <td>-0.182897</td>\n",
       "      <td>0.947976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1662</th>\n",
       "      <td>INFP</td>\n",
       "      <td>'I used to think that maturity was burning bri...</td>\n",
       "      <td>27.38</td>\n",
       "      <td>148.0304</td>\n",
       "      <td>'i used to think that maturity was burning bri...</td>\n",
       "      <td>I</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>P</td>\n",
       "      <td>0.460996</td>\n",
       "      <td>0.223880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3338</th>\n",
       "      <td>INFP</td>\n",
       "      <td>'I get typed as both a 4w5 and 5w6 as well but...</td>\n",
       "      <td>20.94</td>\n",
       "      <td>157.8736</td>\n",
       "      <td>'i get typed as both a &lt;NUM&gt; w &lt;NUM&gt; and &lt;NUM&gt;...</td>\n",
       "      <td>I</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>P</td>\n",
       "      <td>-0.575671</td>\n",
       "      <td>0.428221</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      type                                              posts  \\\n",
       "1228  INFP  'We are mandarin speakers.  He receive educati...   \n",
       "1290  ISTP  'Nope.  Not now, not ever.  I'm too busy with ...   \n",
       "6756  ENFJ  'That's the only one I haven't gotten to read ...   \n",
       "1662  INFP  'I used to think that maturity was burning bri...   \n",
       "3338  INFP  'I get typed as both a 4w5 and 5w6 as well but...   \n",
       "\n",
       "      Average Words Per Comment  Variance of Word Counts  \\\n",
       "1228                      16.78                 187.3024   \n",
       "1290                      24.38                 145.0304   \n",
       "6756                      23.38                 182.9104   \n",
       "1662                      27.38                 148.0304   \n",
       "3338                      20.94                 157.8736   \n",
       "\n",
       "                                          Cleaned Posts IE NS TF JP  \\\n",
       "1228  'we are mandarin speakers. he receive educatio...  I  N  F  P   \n",
       "1290  'nope. not now, not ever. i'm too busy with wo...  I  S  T  P   \n",
       "6756  'that's the only one i haven't gotten to read ...  E  N  F  J   \n",
       "1662  'i used to think that maturity was burning bri...  I  N  F  P   \n",
       "3338  'i get typed as both a <NUM> w <NUM> and <NUM>...  I  N  F  P   \n",
       "\n",
       "      Average Words Per Comment Scaled  Variance of Word Counts Scaled  \n",
       "1228                         -1.245319                        1.039153  \n",
       "1290                         -0.021923                        0.161601  \n",
       "6756                         -0.182897                        0.947976  \n",
       "1662                          0.460996                        0.223880  \n",
       "3338                         -0.575671                        0.428221  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre.train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6940,)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_posts = pre.train['Cleaned Posts'].values\n",
    "cleaned_posts.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Words to Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jinli/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 97151 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "maxlen = 20 # maximum number of words, the rest of the comment would be cut off\n",
    "# 20 for now, but we actually do not want a maximum length\n",
    "max_words = 10000\n",
    "embedding_dim = 100\n",
    "embeddings_index = em.get_GloVe()\n",
    "word_input, word_index = em.map_words_to_int(cleaned_posts, max_words, maxlen)\n",
    "\n",
    "embedding_matrix = em.create_embedding_matrix (\n",
    "    word_index, \n",
    "    embeddings_index, \n",
    "    max_words, \n",
    "    embedding_dim\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (6940, 20)\n",
      "Shape of label tensor: (6940,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 9, 15,  0, ...,  2, 11,  3])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = pre.train['type']\n",
    "\n",
    "print('Shape of data tensor:', word_input.shape)\n",
    "print('Shape of label tensor:', labels.shape)\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "lab_encoder = LabelEncoder()\n",
    "label_encoded = lab_encoder.fit_transform(labels)\n",
    "label_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ENFJ', 'ENFP', 'ENTJ', 'ENTP', 'ESFJ', 'ESFP', 'ESTJ', 'ESTP',\n",
       "       'INFJ', 'INFP', 'INTJ', 'INTP', 'ISFJ', 'ISFP', 'ISTJ', 'ISTP'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lab_encoder.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample Model Training (Results are not meaningful here)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Flatten, Dense\n",
    "\n",
    "def get_model():\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(max_words, embedding_dim, input_length=maxlen))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(16, activation='sigmoid'))\n",
    "    model.compile(optimizer='rmsprop',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['acc'])\n",
    "    model.layers[0].set_weights([embedding_matrix])\n",
    "    model.layers[0].trainable = False\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 20, 100)           1000000   \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 2000)              0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 32)                64032     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 16)                528       \n",
      "=================================================================\n",
      "Total params: 2,064,560\n",
      "Trainable params: 1,064,560\n",
      "Non-trainable params: 1,000,000\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jinli/anaconda3/lib/python3.6/site-packages/keras/engine/training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    }
   ],
   "source": [
    "get_model().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jinli/anaconda3/lib/python3.6/site-packages/keras/engine/training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
      "  'Discrepancy between trainable weights and collected trainable'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "6940/6940 [==============================] - 3s 381us/step - loss: 2.3475 - acc: 0.2075\n",
      "Epoch 2/3\n",
      "6940/6940 [==============================] - 2s 322us/step - loss: 2.2271 - acc: 0.2111\n",
      "Epoch 3/3\n",
      "6940/6940 [==============================] - 2s 348us/step - loss: 2.1181 - acc: 0.2170\n",
      "2313/2313 [==============================] - 0s 65us/step\n",
      "Epoch 1/3\n",
      "6940/6940 [==============================] - 2s 352us/step - loss: 2.3405 - acc: 0.1793\n",
      "Epoch 2/3\n",
      "6940/6940 [==============================] - 2s 347us/step - loss: 2.2353 - acc: 0.2115\n",
      "Epoch 3/3\n",
      "6940/6940 [==============================] - 2s 335us/step - loss: 2.1356 - acc: 0.2140\n",
      "2313/2313 [==============================] - 0s 56us/step\n",
      "Epoch 1/3\n",
      "6940/6940 [==============================] - 3s 382us/step - loss: 2.3329 - acc: 0.2056\n",
      "Epoch 2/3\n",
      "6940/6940 [==============================] - 2s 291us/step - loss: 2.2343 - acc: 0.2114\n",
      "Epoch 3/3\n",
      "6940/6940 [==============================] - 2s 287us/step - loss: 2.1291 - acc: 0.2141\n",
      "2313/2313 [==============================] - 0s 65us/step\n"
     ]
    }
   ],
   "source": [
    "k = 3\n",
    "num_validation_samples = len(word_input) // k\n",
    "\n",
    "np.random.shuffle(word_input)\n",
    "\n",
    "validation_scores = []\n",
    "for fold in range(k):\n",
    "    validation_data = word_input[num_validation_samples * fold:\n",
    "                                 num_validation_samples * (fold + 1)]\n",
    "    validation_label = label_encoded[num_validation_samples * fold:\n",
    "                                 num_validation_samples * (fold + 1)]\n",
    "#     training_data = word_input[:num_validation_samples * fold] + \\\n",
    "#         word_input[num_validation_samples * (fold + 1):]\n",
    "    training_data = np.vstack((\n",
    "        word_input[:num_validation_samples * fold],\n",
    "        word_input[num_validation_samples * (fold + 1):]\n",
    "    ))\n",
    "\n",
    "    model = get_model()\n",
    "    model.fit(\n",
    "        word_input,\n",
    "        label_encoded,\n",
    "        epochs=3,\n",
    "        batch_size=32,\n",
    "    )\n",
    "    validation_score = model.evaluate (validation_data, validation_label)[1] # get the accuracy\n",
    "    validation_scores.append(validation_score)\n",
    "validation_score = np.average(validation_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "      <th>Average Words Per Comment</th>\n",
       "      <th>Variance of Word Counts</th>\n",
       "      <th>Cleaned Posts</th>\n",
       "      <th>IE</th>\n",
       "      <th>NS</th>\n",
       "      <th>TF</th>\n",
       "      <th>JP</th>\n",
       "      <th>Average Words Per Comment Scaled</th>\n",
       "      <th>Variance of Word Counts Scaled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7814</th>\n",
       "      <td>INFP</td>\n",
       "      <td>'Macona , it depends if the big family has ext...</td>\n",
       "      <td>33.16</td>\n",
       "      <td>70.600400</td>\n",
       "      <td>'macona , it depends if the big family has ext...</td>\n",
       "      <td>I</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>P</td>\n",
       "      <td>1.371698</td>\n",
       "      <td>-1.364000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4635</th>\n",
       "      <td>ENFJ</td>\n",
       "      <td>'My Brother is an ISTP and oddly enough I get ...</td>\n",
       "      <td>29.76</td>\n",
       "      <td>169.232400</td>\n",
       "      <td>'my brother is an istp and oddly enough i get ...</td>\n",
       "      <td>E</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>J</td>\n",
       "      <td>0.829438</td>\n",
       "      <td>0.660141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3509</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>'I do this but my violent reaction is to give ...</td>\n",
       "      <td>25.36</td>\n",
       "      <td>163.504400</td>\n",
       "      <td>'i do this but my violent reaction is to give ...</td>\n",
       "      <td>I</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>J</td>\n",
       "      <td>0.127690</td>\n",
       "      <td>0.542590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1882</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>'I do this all the time in relation to people,...</td>\n",
       "      <td>19.86</td>\n",
       "      <td>68.322581</td>\n",
       "      <td>'i do this all the time in relation to people,...</td>\n",
       "      <td>I</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>J</td>\n",
       "      <td>-0.749495</td>\n",
       "      <td>-1.410746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2950</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>'The title of this thread is misleading; there...</td>\n",
       "      <td>25.58</td>\n",
       "      <td>107.344045</td>\n",
       "      <td>'the title of this thread is misleading; there...</td>\n",
       "      <td>I</td>\n",
       "      <td>N</td>\n",
       "      <td>T</td>\n",
       "      <td>J</td>\n",
       "      <td>0.162777</td>\n",
       "      <td>-0.609941</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      type                                              posts  \\\n",
       "7814  INFP  'Macona , it depends if the big family has ext...   \n",
       "4635  ENFJ  'My Brother is an ISTP and oddly enough I get ...   \n",
       "3509  INFJ  'I do this but my violent reaction is to give ...   \n",
       "1882  INFJ  'I do this all the time in relation to people,...   \n",
       "2950  INTJ  'The title of this thread is misleading; there...   \n",
       "\n",
       "      Average Words Per Comment  Variance of Word Counts  \\\n",
       "7814                      33.16                70.600400   \n",
       "4635                      29.76               169.232400   \n",
       "3509                      25.36               163.504400   \n",
       "1882                      19.86                68.322581   \n",
       "2950                      25.58               107.344045   \n",
       "\n",
       "                                          Cleaned Posts IE NS TF JP  \\\n",
       "7814  'macona , it depends if the big family has ext...  I  N  F  P   \n",
       "4635  'my brother is an istp and oddly enough i get ...  E  N  F  J   \n",
       "3509  'i do this but my violent reaction is to give ...  I  N  F  J   \n",
       "1882  'i do this all the time in relation to people,...  I  N  F  J   \n",
       "2950  'the title of this thread is misleading; there...  I  N  T  J   \n",
       "\n",
       "      Average Words Per Comment Scaled  Variance of Word Counts Scaled  \n",
       "7814                          1.371698                       -1.364000  \n",
       "4635                          0.829438                        0.660141  \n",
       "3509                          0.127690                        0.542590  \n",
       "1882                         -0.749495                       -1.410746  \n",
       "2950                          0.162777                       -0.609941  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pre.test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>posts</th>\n",
       "      <th>Average Words Per Comment</th>\n",
       "      <th>Variance of Word Counts</th>\n",
       "      <th>Cleaned Posts</th>\n",
       "      <th>IE</th>\n",
       "      <th>NS</th>\n",
       "      <th>TF</th>\n",
       "      <th>JP</th>\n",
       "      <th>Average Words Per Comment Scaled</th>\n",
       "      <th>Variance of Word Counts Scaled</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7814</th>\n",
       "      <td>INFP</td>\n",
       "      <td>'Macona , it depends if the big family has ext...</td>\n",
       "      <td>33.16</td>\n",
       "      <td>70.600400</td>\n",
       "      <td>'macona , it depends if the big family has ext...</td>\n",
       "      <td>I</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>P</td>\n",
       "      <td>1.371698</td>\n",
       "      <td>-1.364000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4635</th>\n",
       "      <td>ENFJ</td>\n",
       "      <td>'My Brother is an ISTP and oddly enough I get ...</td>\n",
       "      <td>29.76</td>\n",
       "      <td>169.232400</td>\n",
       "      <td>'my brother is an istp and oddly enough i get ...</td>\n",
       "      <td>E</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>J</td>\n",
       "      <td>0.829438</td>\n",
       "      <td>0.660141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3509</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>'I do this but my violent reaction is to give ...</td>\n",
       "      <td>25.36</td>\n",
       "      <td>163.504400</td>\n",
       "      <td>'i do this but my violent reaction is to give ...</td>\n",
       "      <td>I</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>J</td>\n",
       "      <td>0.127690</td>\n",
       "      <td>0.542590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1882</th>\n",
       "      <td>INFJ</td>\n",
       "      <td>'I do this all the time in relation to people,...</td>\n",
       "      <td>19.86</td>\n",
       "      <td>68.322581</td>\n",
       "      <td>'i do this all the time in relation to people,...</td>\n",
       "      <td>I</td>\n",
       "      <td>N</td>\n",
       "      <td>F</td>\n",
       "      <td>J</td>\n",
       "      <td>-0.749495</td>\n",
       "      <td>-1.410746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2950</th>\n",
       "      <td>INTJ</td>\n",
       "      <td>'The title of this thread is misleading; there...</td>\n",
       "      <td>25.58</td>\n",
       "      <td>107.344045</td>\n",
       "      <td>'the title of this thread is misleading; there...</td>\n",
       "      <td>I</td>\n",
       "      <td>N</td>\n",
       "      <td>T</td>\n",
       "      <td>J</td>\n",
       "      <td>0.162777</td>\n",
       "      <td>-0.609941</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      type                                              posts  \\\n",
       "7814  INFP  'Macona , it depends if the big family has ext...   \n",
       "4635  ENFJ  'My Brother is an ISTP and oddly enough I get ...   \n",
       "3509  INFJ  'I do this but my violent reaction is to give ...   \n",
       "1882  INFJ  'I do this all the time in relation to people,...   \n",
       "2950  INTJ  'The title of this thread is misleading; there...   \n",
       "\n",
       "      Average Words Per Comment  Variance of Word Counts  \\\n",
       "7814                      33.16                70.600400   \n",
       "4635                      29.76               169.232400   \n",
       "3509                      25.36               163.504400   \n",
       "1882                      19.86                68.322581   \n",
       "2950                      25.58               107.344045   \n",
       "\n",
       "                                          Cleaned Posts IE NS TF JP  \\\n",
       "7814  'macona , it depends if the big family has ext...  I  N  F  P   \n",
       "4635  'my brother is an istp and oddly enough i get ...  E  N  F  J   \n",
       "3509  'i do this but my violent reaction is to give ...  I  N  F  J   \n",
       "1882  'i do this all the time in relation to people,...  I  N  F  J   \n",
       "2950  'the title of this thread is misleading; there...  I  N  T  J   \n",
       "\n",
       "      Average Words Per Comment Scaled  Variance of Word Counts Scaled  \n",
       "7814                          1.371698                       -1.364000  \n",
       "4635                          0.829438                        0.660141  \n",
       "3509                          0.127690                        0.542590  \n",
       "1882                         -0.749495                       -1.410746  \n",
       "2950                          0.162777                       -0.609941  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pre.test\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 47539 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "test_cleaned_posts = test['Cleaned Posts'].values\n",
    "test_labels = test['type']\n",
    "\n",
    "test_word_input, word_index_test = em.map_words_to_int(test_cleaned_posts, max_words, maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1735/1735 [==============================] - 0s 39us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.364882653316091, 0.21152737754737952]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_label_encoded = lab_encoder.fit_transform(test_labels)\n",
    "model.evaluate (test_word_input, test_label_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
